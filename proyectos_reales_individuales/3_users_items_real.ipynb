{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo users_items.parquet y users_items.csv creado con exito!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['open', '-R', '/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_para_Render/users_items.parquet'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "import pandas as pd\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "archivo = '/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_ORIGINALES/json descomprimidos/3_users_items.json'\n",
    "\n",
    "data = []\n",
    "\n",
    "with open(archivo, 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        try:\n",
    "            json_data = ast.literal_eval(line)\n",
    "            data.append(json_data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error en la línea: {line}\")\n",
    "            continue\n",
    "\n",
    "df_3_users_items = pd.DataFrame(data)\n",
    "\n",
    "# Hacemos un csv para ver los datos originales:\n",
    "df_3_users_items.to_csv('/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_ORIGINALES/csv/users_items_ORIGINAL.csv', index=False)\n",
    "\n",
    "\n",
    "# Hacemos una copia para continuar trabajando con ella y no perder los datos originales:\n",
    "df_3_users_items_copy = df_3_users_items.copy()\n",
    "\n",
    "# Con el objeto de trabajar con datos de calidad, sacaremos las filas que contengan listas vacías en la columna 'items' del tipo[], pero para ello debemos convertir los valores de la columna 'items' a cadenas, ya que actualmente son listas.\n",
    "\n",
    "# Convertir los valores de la columna 'items' a cadenas\n",
    "df_3_users_items_copy['items'] = df_3_users_items_copy['items'].astype(str)\n",
    "\n",
    "# Eliminar las filas donde la celda en la columna 'items' sea una lista vacía o una cadena que contiene solo corchetes\n",
    "df_3_users_items_copy[df_3_users_items_copy['items'].str.strip(\"[]\").str.strip() != \"\"]\n",
    "\n",
    "# Ahora df contendrá solo las filas donde la celda en la columna 'items' no sea una lista vacía ni una cadena que contenga solo corchetes\n",
    "\n",
    "#Convertir la columna 'items' a una lista de diccionarios:\n",
    "\n",
    "df_3_users_items_copy['items'] = df_3_users_items_copy['items'].apply(ast.literal_eval)\n",
    "\n",
    "#La función ast.literal_eval convierte el string en una estructura de datos de Python (en este caso, una lista de diccionarios).\n",
    "\n",
    "# Crear un nuevo DataFrame con todas las filas explodidas\n",
    "df_3_users_items_copy1 = df_3_users_items_copy.explode('items', ignore_index=True)\n",
    "\n",
    "# Crear un DataFrame con los diccionarios normalizados\n",
    "df_3_users_items_copy2 = pd.json_normalize(df_3_users_items_copy1['items'])\n",
    "\n",
    "# Agregar las columnas adicionales del DataFrame original\n",
    "df_3_users_items_copy3 = pd.concat([df_3_users_items_copy1, df_3_users_items_copy2], axis=1)\n",
    "\n",
    "# Eliminar las columnas 'steam_id', 'user_url', 'items' y 'playtime_2weeks' ya que no las necesitamos para el análisis:\n",
    "\n",
    "df_3_users_items_copy4 = df_3_users_items_copy3.drop(['steam_id', 'user_url', 'items', 'playtime_2weeks'], axis=1)\n",
    "\n",
    "# Dejaremos solo 2000 filas elegidas al azar para hacer pruebas con menos datos y un random_state chico para no perder informacion dado el tipo de dataset que tenemos:\n",
    "df_3_users_items_copy5=df_3_users_items_copy4.sample(2000, random_state=8)\n",
    "\n",
    "# Y reindexamos los indices:\n",
    "df_3_users_items_copy5.reset_index(drop=True, inplace=True)\n",
    "\n",
    " # Lo comprimimos a parquet, colocandolo en la carpeta de datasets para render y su nombre original:\n",
    "df_3_users_items_copy5.to_parquet('/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_para_Render/users_items.parquet')\n",
    "\n",
    "# Generamos un CSV con los datos:\n",
    "df_3_users_items_copy5.to_csv('/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_para_Render/users_items.csv', index=False)\n",
    "\n",
    " # Imprimimos entonces el exito de la operacion y dejamos el link para acceder al archivo:\n",
    "print('Archivo users_items.parquet y users_items.csv creado con exito!')\n",
    "\n",
    "# Y dejamos el link para acceder a los archivos, para ello definimos las rutas:\n",
    "file_path = os.path.abspath('/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_para_Render/users_items.parquet')\n",
    "\n",
    "# Define la ruta del archivo CSV\n",
    "csv_file_path = os.path.abspath('/Users/luisalbertocerelli/Desktop/00-Todo/Data Science/01-Full Time/TI_1/Datasets_para_Render/users_items.csv')\n",
    "\n",
    "# Abre la ubicación del archivo CSV en Finder\n",
    "subprocess.run(['open', '-R', csv_file_path])\n",
    "\n",
    "# Abre la ubicación del archivo en Finder (Mac)\n",
    "subprocess.run(['open', '-R', file_path])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peso del archivo users_items.parquet: 28664.71 KB\n",
      "Peso del archivo users_items.csv: 248710.33 KB\n"
     ]
    }
   ],
   "source": [
    "# Vemos el peso en kb de los archivos generados:\n",
    "print(f'Peso del archivo users_items.parquet: {os.path.getsize(file_path) / 1024:.2f} KB')\n",
    "print(f'Peso del archivo users_items.csv: {os.path.getsize(csv_file_path) / 1024:.2f} KB')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
